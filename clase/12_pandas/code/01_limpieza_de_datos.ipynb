{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pandas en practica: Tipos, Missings, Memoria y Pipelines\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sonder-art/fdd_p26/blob/main/clase/12_pandas/code/01_limpieza_de_datos.ipynb)\n",
        "\n",
        "Este notebook cubre la parte hands-on del modulo. Vamos a trabajar con un dataset generado que tiene todos los problemas tipicos de datos reales: tipos mal inferidos, missings en distintos formatos, columnas pesadas, y codigo lento.\n",
        "\n",
        "**Tiempo estimado**: ~35 minutos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pandas: 2.0.3\n",
            "numpy:  1.24.3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(f\"pandas: {pd.__version__}\")\n",
        "print(f\"numpy:  {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Generar dataset sucio\n",
        "\n",
        "Vamos a crear un DataFrame que simula datos reales con problemas reales: missings, tipos inconsistentes, strings sucios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (100000, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_cliente</th>\n",
              "      <th>nombre</th>\n",
              "      <th>genero</th>\n",
              "      <th>edad</th>\n",
              "      <th>monto</th>\n",
              "      <th>fecha</th>\n",
              "      <th>activo</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Carlos Ruiz</td>\n",
              "      <td></td>\n",
              "      <td>53.0</td>\n",
              "      <td>856.40</td>\n",
              "      <td>not_a_date</td>\n",
              "      <td>0.0</td>\n",
              "      <td>este</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>na</td>\n",
              "      <td>M</td>\n",
              "      <td>47.0</td>\n",
              "      <td>301.38</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NORTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>nan</td>\n",
              "      <td>F</td>\n",
              "      <td>45.0</td>\n",
              "      <td>-720.19</td>\n",
              "      <td>15/02/2024</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Centro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Ana Lopez</td>\n",
              "      <td>F</td>\n",
              "      <td>59.0</td>\n",
              "      <td>213.96</td>\n",
              "      <td>2024-05-10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Sur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>N/A</td>\n",
              "      <td>nan</td>\n",
              "      <td>28.0</td>\n",
              "      <td>787.17</td>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "      <td>Centro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.0</td>\n",
              "      <td>N/A</td>\n",
              "      <td>F</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1363.65</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Norte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.0</td>\n",
              "      <td>null</td>\n",
              "      <td>M</td>\n",
              "      <td>59.0</td>\n",
              "      <td>19.05</td>\n",
              "      <td>not_a_date</td>\n",
              "      <td>1.0</td>\n",
              "      <td>este</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.0</td>\n",
              "      <td>N/A</td>\n",
              "      <td>M</td>\n",
              "      <td>33.0</td>\n",
              "      <td>951.28</td>\n",
              "      <td>nan</td>\n",
              "      <td>1.0</td>\n",
              "      <td>este</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9.0</td>\n",
              "      <td>Ana Lopez</td>\n",
              "      <td>M</td>\n",
              "      <td>52.0</td>\n",
              "      <td>-1459.81</td>\n",
              "      <td>not_a_date</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Oeste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10.0</td>\n",
              "      <td>N/A</td>\n",
              "      <td>F</td>\n",
              "      <td>39.0</td>\n",
              "      <td>199.45</td>\n",
              "      <td>2024-05-10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sur</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_cliente       nombre genero  edad    monto       fecha  activo  region\n",
              "0         1.0  Carlos Ruiz         53.0   856.40  not_a_date     0.0    este\n",
              "1         2.0           na      M  47.0   301.38  2024-01-15     0.0   NORTE\n",
              "2         3.0          nan      F  45.0  -720.19  15/02/2024     1.0  Centro\n",
              "3         4.0    Ana Lopez      F  59.0   213.96  2024-05-10     1.0     Sur\n",
              "4         5.0          N/A    nan  28.0   787.17                 1.0  Centro\n",
              "5         6.0          N/A      F  47.0  1363.65  2024-01-15     1.0   Norte\n",
              "6         7.0         null      M  59.0    19.05  not_a_date     1.0    este\n",
              "7         8.0          N/A      M  33.0   951.28         nan     1.0    este\n",
              "8         9.0    Ana Lopez      M  52.0 -1459.81  not_a_date     1.0   Oeste\n",
              "9        10.0          N/A      F  39.0   199.45  2024-05-10     NaN     Sur"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "n = 100_000\n",
        "\n",
        "df_sucio = pd.DataFrame({\n",
        "    # ID: entero, pero vamos a meter missings para forzar float\n",
        "    \"id_cliente\": np.where(\n",
        "        np.random.random(n) < 0.02,\n",
        "        np.nan,\n",
        "        np.arange(1, n + 1).astype(float),\n",
        "    ),\n",
        "    # Nombre: strings con variaciones de missing\n",
        "    \"nombre\": np.random.choice(\n",
        "        [\"Ana Lopez\", \"Carlos Ruiz\", \"  maria garcia \", \"PEDRO SANCHEZ\",\n",
        "         \"\", \"N/A\", \"null\", \"na\", np.nan, \"Sofia Torres\"],\n",
        "        size=n,\n",
        "    ),\n",
        "    # Genero: categorico con missings disfrazados\n",
        "    \"genero\": np.random.choice(\n",
        "        [\"M\", \"F\", \"NB\", \"N/A\", \"\", np.nan, \"No especificado\"],\n",
        "        size=n,\n",
        "        p=[0.35, 0.35, 0.05, 0.05, 0.05, 0.10, 0.05],\n",
        "    ),\n",
        "    # Edad: numerico con missings y outliers\n",
        "    \"edad\": np.where(\n",
        "        np.random.random(n) < 0.08,\n",
        "        np.nan,\n",
        "        np.clip(np.random.normal(35, 12, n).astype(int), -5, 200),\n",
        "    ),\n",
        "    # Monto: float con algunos negativos (errores) y missings\n",
        "    \"monto\": np.where(\n",
        "        np.random.random(n) < 0.05,\n",
        "        np.nan,\n",
        "        np.round(np.random.exponential(500, n) * np.random.choice([1, 1, 1, -1], n), 2),\n",
        "    ),\n",
        "    # Fecha: string con formatos mixtos\n",
        "    \"fecha\": np.random.choice(\n",
        "        [\"2024-01-15\", \"15/02/2024\", \"2024-03-20\", \"20-04-2024\",\n",
        "         \"2024-05-10\", \"\", np.nan, \"not_a_date\"],\n",
        "        size=n,\n",
        "    ),\n",
        "    # Activo: booleano con missings\n",
        "    \"activo\": np.random.choice(\n",
        "        [True, False, np.nan],\n",
        "        size=n,\n",
        "        p=[0.6, 0.3, 0.1],\n",
        "    ),\n",
        "    # Region: categorico con muchas repeticiones (candidato a category)\n",
        "    \"region\": np.random.choice(\n",
        "        [\"Norte\", \"Sur\", \"Este\", \"Oeste\", \"Centro\",\n",
        "         \"norte\", \"NORTE\", \"Sur \", \" este\"],\n",
        "        size=n,\n",
        "    ),\n",
        "})\n",
        "\n",
        "print(f\"Shape: {df_sucio.shape}\")\n",
        "df_sucio.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Diagnostico inicial\n",
        "\n",
        "Antes de tocar nada, diagnostica. Esto deberia ser lo **primero** que haces con cualquier dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 8 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   id_cliente  98023 non-null   float64\n",
            " 1   nombre      100000 non-null  object \n",
            " 2   genero      100000 non-null  object \n",
            " 3   edad        91895 non-null   float64\n",
            " 4   monto       95026 non-null   float64\n",
            " 5   fecha       100000 non-null  object \n",
            " 6   activo      90032 non-null   float64\n",
            " 7   region      100000 non-null  object \n",
            "dtypes: float64(4), object(4)\n",
            "memory usage: 26.9 MB\n"
          ]
        }
      ],
      "source": [
        "# info() es tu mejor amigo: tipos, nulls, y memoria en un solo comando\n",
        "df_sucio.info(memory_usage=\"deep\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "% missings por columna:\n",
            "id_cliente    1.98\n",
            "nombre        0.00\n",
            "genero        0.00\n",
            "edad          8.10\n",
            "monto         4.97\n",
            "fecha         0.00\n",
            "activo        9.97\n",
            "region        0.00\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Porcentaje de missings por columna\n",
        "print(\"% missings por columna:\")\n",
        "print(df_sucio.isna().mean().round(4) * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipos:\n",
            "id_cliente    float64\n",
            "nombre         object\n",
            "genero         object\n",
            "edad          float64\n",
            "monto         float64\n",
            "fecha          object\n",
            "activo        float64\n",
            "region         object\n",
            "dtype: object\n",
            "\n",
            "Observaciones:\n",
            "- id_cliente es float64 (deberia ser entero, pero NaN lo fuerza a float)\n",
            "- nombre, genero, fecha, region son object (strings mezclados con NaN)\n",
            "- activo es object (deberia ser bool, pero NaN lo corrompe)\n"
          ]
        }
      ],
      "source": [
        "# Tipos de datos — nota como pandas eligio los tipos\n",
        "print(\"Tipos:\")\n",
        "print(df_sucio.dtypes)\n",
        "print()\n",
        "print(\"Observaciones:\")\n",
        "print(\"- id_cliente es float64 (deberia ser entero, pero NaN lo fuerza a float)\")\n",
        "print(\"- nombre, genero, fecha, region son object (strings mezclados con NaN)\")\n",
        "print(\"- activo es object (deberia ser bool, pero NaN lo corrompe)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. El problema de `np.nan`\n",
        "\n",
        "`np.nan` es un `float` de IEEE 754. Esta decision tecnica tiene consecuencias reales para tu analisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type(np.nan) = <class 'float'>\n",
            "np.nan == np.nan = False\n",
            "\n",
            "Serie con NaN: dtype = float64\n",
            "Valores: [1.0, 2.0, 3.0, nan, 5.0]\n",
            "\n",
            "Serie bool con NaN: dtype = object\n",
            "\n",
            "np.nan in [np.nan] = True\n",
            "value_counts():\n",
            "1.0    1\n",
            "2.0    1\n",
            "Name: count, dtype: int64\n",
            "value_counts(dropna=False):\n",
            "NaN    2\n",
            "1.0    1\n",
            "2.0    1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# np.nan es float\n",
        "print(f\"type(np.nan) = {type(np.nan)}\")\n",
        "print(f\"np.nan == np.nan = {np.nan == np.nan}\")  # False! IEEE 754\n",
        "print()\n",
        "\n",
        "# Consecuencia 1: enteros con NaN se promueven a float\n",
        "s_int = pd.Series([1, 2, 3, np.nan, 5])\n",
        "print(f\"Serie con NaN: dtype = {s_int.dtype}\")  # float64, no int\n",
        "print(f\"Valores: {s_int.tolist()}\")  # 1.0, 2.0, 3.0, nan, 5.0\n",
        "print()\n",
        "\n",
        "# Consecuencia 2: booleanos con NaN se vuelven object\n",
        "s_bool = pd.Series([True, False, np.nan])\n",
        "print(f\"Serie bool con NaN: dtype = {s_bool.dtype}\")  # object!\n",
        "print()\n",
        "\n",
        "# Consecuencia 3: NaN rompe comparaciones\n",
        "print(f\"np.nan in [np.nan] = {np.nan in [np.nan]}\")  # True (Python 'is')\n",
        "datos = pd.Series([1, np.nan, 2, np.nan])\n",
        "print(f\"value_counts():\\n{datos.value_counts()}\")  # NaN excluido por default\n",
        "print(f\"value_counts(dropna=False):\\n{datos.value_counts(dropna=False)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nullable Int64: dtype = Int64\n",
            "Valores: [1, 2, 3, <NA>, 5]\n",
            "\n",
            "pd.NA + 1 = <NA>\n",
            "pd.NA | True = True\n",
            "pd.NA & False = False\n"
          ]
        }
      ],
      "source": [
        "# La solucion: nullable dtypes con pd.NA\n",
        "s_nullable = pd.array([1, 2, 3, pd.NA, 5], dtype=\"Int64\")  # I mayuscula!\n",
        "print(f\"Nullable Int64: dtype = {pd.Series(s_nullable).dtype}\")\n",
        "print(f\"Valores: {list(s_nullable)}\")  # 1, 2, 3, <NA>, 5 — enteros reales\n",
        "print()\n",
        "\n",
        "# pd.NA vs np.nan: propagacion consistente\n",
        "print(f\"pd.NA + 1 = {pd.NA + 1}\")     # <NA> — propaga\n",
        "print(f\"pd.NA | True = {pd.NA | True}\")  # True — logica de 3 valores\n",
        "print(f\"pd.NA & False = {pd.NA & False}\")  # False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Missings por tipo de dato\n",
        "\n",
        "Los missings se comportan distinto segun el tipo de columna. Vamos caso por caso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Missings numericos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Media original (ignorando NaN): 34.52\n",
            "N original: 91895\n",
            "\n",
            "Media con fillna(0): 31.72  ← sesgo hacia abajo\n",
            "Media con fillna(median): 34.48  ← preserva mejor\n",
            "Media con dropna: 34.52, N=91895\n",
            "\n",
            "Std original: 12.03\n",
            "Std fillna(0): 14.89  ← inflada por los ceros\n",
            "Std fillna(median): 11.54  ← reducida (comprime hacia centro)\n"
          ]
        }
      ],
      "source": [
        "# El peligro de fillna(0)\n",
        "edad = df_sucio[\"edad\"].copy()\n",
        "\n",
        "print(f\"Media original (ignorando NaN): {edad.mean():.2f}\")\n",
        "print(f\"N original: {edad.notna().sum()}\")\n",
        "print()\n",
        "\n",
        "# fillna(0): introduce sesgo si 0 no es un valor valido\n",
        "edad_fill0 = edad.fillna(0)\n",
        "print(f\"Media con fillna(0): {edad_fill0.mean():.2f}  ← sesgo hacia abajo\")\n",
        "\n",
        "# fillna(mediana): mejor para distribucion simetrica\n",
        "edad_fillmed = edad.fillna(edad.median())\n",
        "print(f\"Media con fillna(median): {edad_fillmed.mean():.2f}  ← preserva mejor\")\n",
        "\n",
        "# dropna: reduce N pero no introduce sesgo\n",
        "print(f\"Media con dropna: {edad.dropna().mean():.2f}, N={edad.dropna().shape[0]}\")\n",
        "print()\n",
        "\n",
        "# Impacto en varianza\n",
        "print(f\"Std original: {edad.std():.2f}\")\n",
        "print(f\"Std fillna(0): {edad_fill0.std():.2f}  ← inflada por los ceros\")\n",
        "print(f\"Std fillna(median): {edad_fillmed.std():.2f}  ← reducida (comprime hacia centro)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipo original: float64 — IDs son 1.0, 2.0, 3.0...\n",
            "Tipo nullable: Int64 — IDs son 1, 2, 3, <NA>\n",
            "\n",
            "Primeros valores con missing:\n",
            "  float64: [72.0, nan, 74.0]\n",
            "  Int64:   [72, <NA>, 74]\n"
          ]
        }
      ],
      "source": [
        "# Nullable Int64 vs float64\n",
        "id_float = df_sucio[\"id_cliente\"]\n",
        "id_nullable = df_sucio[\"id_cliente\"].astype(\"Int64\")\n",
        "\n",
        "print(f\"Tipo original: {id_float.dtype} — IDs son 1.0, 2.0, 3.0...\")\n",
        "print(f\"Tipo nullable: {id_nullable.dtype} — IDs son 1, 2, 3, <NA>\")\n",
        "print()\n",
        "print(\"Primeros valores con missing:\")\n",
        "mask = id_float.isna()\n",
        "idx = mask[mask].index[0]\n",
        "print(f\"  float64: {id_float.iloc[idx-1:idx+2].tolist()}\")\n",
        "print(f\"  Int64:   {id_nullable.iloc[idx-1:idx+2].tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Missings en texto y categoricos\n",
        "\n",
        "En columnas de texto, los missings vienen disfrazados: `NaN`, `\"\"`, `\"N/A\"`, `\"null\"`, `\"na\"`, espacios..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "value_counts de genero (raw):\n",
            "genero\n",
            "F                  35024\n",
            "M                  34975\n",
            "nan                10109\n",
            "NB                  5047\n",
            "No especificado     4990\n",
            "N/A                 4986\n",
            "                    4869\n",
            "Name: count, dtype: int64\n",
            "\n",
            "NaN, \"\", \"N/A\", y \"No especificado\" son todos el mismo concepto:\n",
            "  datos faltantes. Pero pandas no lo sabe.\n"
          ]
        }
      ],
      "source": [
        "# ¿Cuantos \"missings reales\" hay en genero?\n",
        "print(\"value_counts de genero (raw):\")\n",
        "print(df_sucio[\"genero\"].value_counts(dropna=False))\n",
        "print()\n",
        "print('NaN, \"\", \"N/A\", y \"No especificado\" son todos el mismo concepto:')\n",
        "print(\"  datos faltantes. Pero pandas no lo sabe.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Despues de normalizar:\n",
            "genero\n",
            "F       35024\n",
            "M       34975\n",
            "<NA>    14845\n",
            "nan     10109\n",
            "NB       5047\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Patron: normalizar missings disfrazados\n",
        "def normalizar_missings_texto(series, extras=None):\n",
        "    \"\"\"Reemplaza variaciones de missing en strings por pd.NA.\"\"\"\n",
        "    valores_missing = {\"\", \"N/A\", \"n/a\", \"na\", \"NA\", \"null\", \"NULL\",\n",
        "                       \"None\", \"none\", \".\", \"-\", \"No especificado\"}\n",
        "    if extras:\n",
        "        valores_missing.update(extras)\n",
        "    resultado = series.copy()\n",
        "    resultado = resultado.str.strip()  # quitar espacios\n",
        "    resultado = resultado.replace(valores_missing, pd.NA)\n",
        "    return resultado\n",
        "\n",
        "genero_limpio = normalizar_missings_texto(df_sucio[\"genero\"])\n",
        "print(\"Despues de normalizar:\")\n",
        "print(genero_limpio.value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "object:    6,166,278 bytes\n",
            "category:    100,983 bytes\n",
            "Ahorro:   98.4%\n"
          ]
        }
      ],
      "source": [
        "# category dtype: ahorra memoria cuando hay pocos valores unicos\n",
        "print(f\"object:   {df_sucio['region'].memory_usage(deep=True):>10,} bytes\")\n",
        "\n",
        "region_cat = df_sucio[\"region\"].astype(\"category\")\n",
        "print(f\"category: {region_cat.memory_usage(deep=True):>10,} bytes\")\n",
        "print(f\"Ahorro:   {1 - region_cat.memory_usage(deep=True) / df_sucio['region'].memory_usage(deep=True):.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Missings en fechas y booleanos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipo: datetime64[ns]\n",
            "Missings (NaT): 37562 (37.6%)\n",
            "  — Incluye NaN originales + strings invalidos como 'not_a_date'\n",
            "\n",
            "Tipo raw: float64\n",
            "Tipo nullable: boolean\n",
            "Valores unicos: [False, True, <NA>]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_164188/2182009145.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  fechas = pd.to_datetime(df_sucio[\"fecha\"], errors=\"coerce\", dayfirst=False)\n"
          ]
        }
      ],
      "source": [
        "# Fechas: NaT es el missing nativo de datetime64\n",
        "fechas = pd.to_datetime(df_sucio[\"fecha\"], errors=\"coerce\", dayfirst=False)\n",
        "print(f\"Tipo: {fechas.dtype}\")\n",
        "print(f\"Missings (NaT): {fechas.isna().sum()} ({fechas.isna().mean():.1%})\")\n",
        "print(f\"  — Incluye NaN originales + strings invalidos como 'not_a_date'\")\n",
        "print()\n",
        "\n",
        "# Booleanos: pd.BooleanDtype\n",
        "activo_raw = df_sucio[\"activo\"]\n",
        "print(f\"Tipo raw: {activo_raw.dtype}\")  # object!\n",
        "\n",
        "activo_nullable = activo_raw.astype(\"boolean\")\n",
        "print(f\"Tipo nullable: {activo_nullable.dtype}\")  # boolean (nullable)\n",
        "print(f\"Valores unicos: {activo_nullable.unique().tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Impacto estadistico de missings\n",
        "\n",
        "El problema mas sutil: tu `n` cambia silenciosamente entre operaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos:\n",
            "  grupo  valor\n",
            "0     A   10.0\n",
            "1     A   20.0\n",
            "2     A    NaN\n",
            "3     A    NaN\n",
            "4     B   10.0\n",
            "5     B   20.0\n",
            "6     B   30.0\n",
            "7     B   40.0\n",
            "\n",
            "mean() por grupo:\n",
            "grupo\n",
            "A    15.0\n",
            "B    25.0\n",
            "Name: valor, dtype: float64\n",
            "\n",
            "count() por grupo:\n",
            "grupo\n",
            "A    2\n",
            "B    4\n",
            "Name: valor, dtype: int64\n",
            "\n",
            "Grupo A: mean=15.0 basado en n=2 (50% missing)\n",
            "Grupo B: mean=25.0 basado en n=4 (0% missing)\n",
            "Comparar estas medias directamente es estadisticamente dudoso.\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo: groupby con distintos missings por grupo\n",
        "ejemplo = pd.DataFrame({\n",
        "    \"grupo\": [\"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\"],\n",
        "    \"valor\": [10, 20, np.nan, np.nan, 10, 20, 30, 40],\n",
        "})\n",
        "\n",
        "print(\"Datos:\")\n",
        "print(ejemplo)\n",
        "print()\n",
        "\n",
        "g = ejemplo.groupby(\"grupo\")[\"valor\"]\n",
        "print(\"mean() por grupo:\")\n",
        "print(g.mean())\n",
        "print()\n",
        "print(\"count() por grupo:\")\n",
        "print(g.count())\n",
        "print()\n",
        "print(\"Grupo A: mean=15.0 basado en n=2 (50% missing)\")\n",
        "print(\"Grupo B: mean=25.0 basado en n=4 (0% missing)\")\n",
        "print(\"Comparar estas medias directamente es estadisticamente dudoso.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Memoria: diagnóstico y optimización\n",
        "\n",
        "Antes de “optimizar”, conviene **medir**: cuánta memoria usa tu DataFrame en total y qué columnas son las más pesadas. Esto suele estar dominado por columnas tipo texto (`object`) y por tipos numéricos más grandes de lo necesario (por ejemplo `float64` cuando `float32` basta)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memoria por columna (MB):\n",
            "Index         0.00\n",
            "id_cliente    0.76\n",
            "nombre        6.12\n",
            "genero        5.63\n",
            "edad          0.76\n",
            "monto         0.76\n",
            "fecha         6.19\n",
            "activo        0.76\n",
            "region        5.88\n",
            "dtype: float64\n",
            "\n",
            "Total: 26.87 MB\n"
          ]
        }
      ],
      "source": [
        "# Memoria actual del dataset sucio\n",
        "mem_antes = df_sucio.memory_usage(deep=True)\n",
        "total_antes = mem_antes.sum()\n",
        "print(\"Memoria por columna (MB):\")\n",
        "print((mem_antes / 1024**2).round(2))\n",
        "print(f\"\\nTotal: {total_antes / 1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparacion de memoria (MB):\n",
            "            antes  despues reduccion\n",
            "Index       0.000    0.000      nan%\n",
            "id_cliente  0.763    0.858      -12%\n",
            "nombre      6.123    6.123        0%\n",
            "genero      5.627    0.096       98%\n",
            "edad        0.763    0.286       63%\n",
            "monto       0.763    0.381       50%\n",
            "fecha       6.187    6.187        0%\n",
            "activo      0.763    0.191       75%\n",
            "region      5.880    0.096       98%\n",
            "\n",
            "Total: 26.87 MB → 14.22 MB\n",
            "Reduccion: 47%\n"
          ]
        }
      ],
      "source": [
        "# Optimizar tipos\n",
        "df_opt = df_sucio.copy()\n",
        "\n",
        "# 1. IDs: float64 → Int64 (nullable)\n",
        "df_opt[\"id_cliente\"] = df_opt[\"id_cliente\"].astype(\"Int64\")\n",
        "\n",
        "# 2. Edad: float64 → Int16 (nullable, rango -32k a 32k, sobra para edad)\n",
        "df_opt[\"edad\"] = df_opt[\"edad\"].astype(\"Int16\")\n",
        "\n",
        "# 3. Monto: float64 → float32 (precision suficiente para montos)\n",
        "df_opt[\"monto\"] = df_opt[\"monto\"].astype(\"float32\")\n",
        "\n",
        "# 4. Strings con pocos unicos → category\n",
        "df_opt[\"genero\"] = df_opt[\"genero\"].astype(\"category\")\n",
        "df_opt[\"region\"] = df_opt[\"region\"].astype(\"category\")\n",
        "\n",
        "# 5. Activo: object → boolean (nullable)\n",
        "df_opt[\"activo\"] = df_opt[\"activo\"].astype(\"boolean\")\n",
        "\n",
        "# 6. Nombre: object → StringDtype\n",
        "df_opt[\"nombre\"] = df_opt[\"nombre\"].astype(\"string\")\n",
        "\n",
        "# Comparar\n",
        "mem_despues = df_opt.memory_usage(deep=True)\n",
        "total_despues = mem_despues.sum()\n",
        "\n",
        "print(\"Comparacion de memoria (MB):\")\n",
        "comparacion = pd.DataFrame({\n",
        "    \"antes\": (mem_antes / 1024**2).round(3),\n",
        "    \"despues\": (mem_despues / 1024**2).round(3),\n",
        "})\n",
        "comparacion[\"reduccion\"] = (1 - comparacion[\"despues\"] / comparacion[\"antes\"]).map(\"{:.0%}\".format)\n",
        "print(comparacion)\n",
        "print(f\"\\nTotal: {total_antes/1024**2:.2f} MB → {total_despues/1024**2:.2f} MB\")\n",
        "print(f\"Reduccion: {1 - total_despues/total_antes:.0%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Pipeline completo con `.pipe()`\n",
        "\n",
        "Ahora vamos a juntar todo en un pipeline limpio y reproducible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Funciones del pipeline ---\n",
        "\n",
        "def validar_schema(df, columnas):\n",
        "    \"\"\"Verifica que las columnas esperadas existan.\"\"\"\n",
        "    faltantes = set(columnas) - set(df.columns)\n",
        "    assert not faltantes, f\"Columnas faltantes: {faltantes}\"\n",
        "    assert len(df) > 0, \"DataFrame vacio\"\n",
        "    return df\n",
        "\n",
        "\n",
        "def normalizar_columnas(df):\n",
        "    \"\"\"Limpia nombres de columnas.\"\"\"\n",
        "    df = df.copy()\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "        .str.strip()\n",
        "        .str.lower()\n",
        "        .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
        "        .str.strip(\"_\")\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "def castear_tipos(df):\n",
        "    \"\"\"Asigna tipos correctos.\"\"\"\n",
        "    return df.assign(\n",
        "        id_cliente=lambda d: d[\"id_cliente\"].astype(\"Int64\"),\n",
        "        edad=lambda d: d[\"edad\"].astype(\"Int16\"),\n",
        "        monto=lambda d: d[\"monto\"].astype(\"float32\"),\n",
        "        activo=lambda d: d[\"activo\"].astype(\"boolean\"),\n",
        "        genero=lambda d: d[\"genero\"].astype(\"string\"),\n",
        "        nombre=lambda d: d[\"nombre\"].astype(\"string\"),\n",
        "        region=lambda d: d[\"region\"].astype(\"string\"),\n",
        "    )\n",
        "\n",
        "\n",
        "def limpiar_texto(df):\n",
        "    \"\"\"Normaliza strings y missings disfrazados.\"\"\"\n",
        "    valores_missing = {\"N/A\", \"n/a\", \"na\", \"NA\", \"null\", \"NULL\",\n",
        "                       \"None\", \"none\", \".\", \"-\", \"No especificado\"}\n",
        "\n",
        "    def limpiar_col(series):\n",
        "        s = series.str.strip().str.lower()\n",
        "        s = s.replace(valores_missing | {\"\"}, pd.NA)\n",
        "        return s\n",
        "\n",
        "    return df.assign(\n",
        "        nombre=lambda d: limpiar_col(d[\"nombre\"]).str.title(),\n",
        "        genero=lambda d: limpiar_col(d[\"genero\"]).str.upper(),\n",
        "        region=lambda d: limpiar_col(d[\"region\"]).str.capitalize(),\n",
        "    )\n",
        "\n",
        "\n",
        "def limpiar_fechas(df):\n",
        "    \"\"\"Parsea fechas, invalidas se vuelven NaT.\"\"\"\n",
        "    return df.assign(\n",
        "        fecha=lambda d: pd.to_datetime(d[\"fecha\"], errors=\"coerce\", dayfirst=False)\n",
        "    )\n",
        "\n",
        "\n",
        "def filtrar_invalidos(df):\n",
        "    \"\"\"Quita filas con problemas irrecuperables.\"\"\"\n",
        "    return (\n",
        "        df\n",
        "        .query(\"edad >= 0 | edad != edad\")  # permitir NaN pero no negativos\n",
        "        .query(\"monto >= 0 | monto != monto\")  # permitir NaN pero no negativos\n",
        "    )\n",
        "\n",
        "\n",
        "def convertir_categorias(df):\n",
        "    \"\"\"Convierte columnas con pocos unicos a category.\"\"\"\n",
        "    return df.assign(\n",
        "        genero=lambda d: d[\"genero\"].astype(\"category\"),\n",
        "        region=lambda d: d[\"region\"].astype(\"category\"),\n",
        "    )\n",
        "\n",
        "\n",
        "def validar_salida(df):\n",
        "    \"\"\"Asserts de cordura sobre el resultado.\"\"\"\n",
        "    assert df[\"id_cliente\"].dropna().is_unique, \"IDs duplicados\"\n",
        "    assert df[\"edad\"].dropna().between(0, 120).all(), \"Edades fuera de rango\"\n",
        "    assert df[\"monto\"].dropna().ge(0).all(), \"Montos negativos\"\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 100,000 → 69,931 (30,069 eliminadas)\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 69931 entries, 0 to 99997\n",
            "Data columns (total 8 columns):\n",
            " #   Column      Non-Null Count  Dtype         \n",
            "---  ------      --------------  -----         \n",
            " 0   id_cliente  68550 non-null  Int64         \n",
            " 1   nombre      41963 non-null  string        \n",
            " 2   genero      63126 non-null  category      \n",
            " 3   edad        69931 non-null  Int16         \n",
            " 4   monto       65356 non-null  float32       \n",
            " 5   fecha       43645 non-null  datetime64[ns]\n",
            " 6   activo      62998 non-null  boolean       \n",
            " 7   region      69931 non-null  category      \n",
            "dtypes: Int16(1), Int64(1), boolean(1), category(2), datetime64[ns](1), float32(1), string(1)\n",
            "memory usage: 6.2 MB\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_164188/1481620905.py:57: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  fecha=lambda d: pd.to_datetime(d[\"fecha\"], errors=\"coerce\", dayfirst=False)\n"
          ]
        }
      ],
      "source": [
        "# --- Ejecutar pipeline ---\n",
        "\n",
        "COLUMNAS_ESPERADAS = [\"id_cliente\", \"nombre\", \"genero\", \"edad\",\n",
        "                      \"monto\", \"fecha\", \"activo\", \"region\"]\n",
        "\n",
        "df_limpio = (\n",
        "    df_sucio\n",
        "    .pipe(validar_schema, COLUMNAS_ESPERADAS)\n",
        "    .pipe(normalizar_columnas)\n",
        "    .pipe(castear_tipos)\n",
        "    .pipe(limpiar_texto)\n",
        "    .pipe(limpiar_fechas)\n",
        "    .pipe(filtrar_invalidos)\n",
        "    .pipe(convertir_categorias)\n",
        "    .pipe(validar_salida)\n",
        ")\n",
        "\n",
        "print(f\"Filas: {len(df_sucio):,} → {len(df_limpio):,} ({len(df_sucio) - len(df_limpio):,} eliminadas)\")\n",
        "print()\n",
        "df_limpio.info(memory_usage=\"deep\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_cliente</th>\n",
              "      <th>nombre</th>\n",
              "      <th>genero</th>\n",
              "      <th>edad</th>\n",
              "      <th>monto</th>\n",
              "      <th>fecha</th>\n",
              "      <th>activo</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Carlos Ruiz</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>53</td>\n",
              "      <td>856.400024</td>\n",
              "      <td>NaT</td>\n",
              "      <td>False</td>\n",
              "      <td>Este</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>M</td>\n",
              "      <td>47</td>\n",
              "      <td>301.380005</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>False</td>\n",
              "      <td>Norte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Ana Lopez</td>\n",
              "      <td>F</td>\n",
              "      <td>59</td>\n",
              "      <td>213.960007</td>\n",
              "      <td>2024-05-10</td>\n",
              "      <td>True</td>\n",
              "      <td>Sur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>NAN</td>\n",
              "      <td>28</td>\n",
              "      <td>787.169983</td>\n",
              "      <td>NaT</td>\n",
              "      <td>True</td>\n",
              "      <td>Centro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>F</td>\n",
              "      <td>47</td>\n",
              "      <td>1363.650024</td>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>True</td>\n",
              "      <td>Norte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>M</td>\n",
              "      <td>59</td>\n",
              "      <td>19.049999</td>\n",
              "      <td>NaT</td>\n",
              "      <td>True</td>\n",
              "      <td>Este</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>M</td>\n",
              "      <td>33</td>\n",
              "      <td>951.280029</td>\n",
              "      <td>NaT</td>\n",
              "      <td>True</td>\n",
              "      <td>Este</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>F</td>\n",
              "      <td>39</td>\n",
              "      <td>199.449997</td>\n",
              "      <td>2024-05-10</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>Sur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>Pedro Sanchez</td>\n",
              "      <td>F</td>\n",
              "      <td>46</td>\n",
              "      <td>1529.199951</td>\n",
              "      <td>NaT</td>\n",
              "      <td>True</td>\n",
              "      <td>Este</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>Sofia Torres</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>31</td>\n",
              "      <td>246.059998</td>\n",
              "      <td>2024-04-20</td>\n",
              "      <td>True</td>\n",
              "      <td>Centro</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id_cliente         nombre genero  edad        monto      fecha  activo  \\\n",
              "0            1    Carlos Ruiz   <NA>    53   856.400024        NaT   False   \n",
              "1            2           <NA>      M    47   301.380005 2024-01-15   False   \n",
              "3            4      Ana Lopez      F    59   213.960007 2024-05-10    True   \n",
              "4            5           <NA>    NAN    28   787.169983        NaT    True   \n",
              "5            6           <NA>      F    47  1363.650024 2024-01-15    True   \n",
              "6            7           <NA>      M    59    19.049999        NaT    True   \n",
              "7            8           <NA>      M    33   951.280029        NaT    True   \n",
              "9           10           <NA>      F    39   199.449997 2024-05-10    <NA>   \n",
              "10          11  Pedro Sanchez      F    46  1529.199951        NaT    True   \n",
              "12          13   Sofia Torres   <NA>    31   246.059998 2024-04-20    True   \n",
              "\n",
              "    region  \n",
              "0     Este  \n",
              "1    Norte  \n",
              "3      Sur  \n",
              "4   Centro  \n",
              "5    Norte  \n",
              "6     Este  \n",
              "7     Este  \n",
              "9      Sur  \n",
              "10    Este  \n",
              "12  Centro  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_limpio.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Formatos: CSV vs Parquet\n",
        "\n",
        "Guardar en el formato correcto es una decision arquitectonica, no estetica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV:     2.85 MB\n",
            "Parquet: 1.32 MB\n",
            "Parquet es 2.2x mas pequeno\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# Guardar en ambos formatos\n",
        "df_limpio.to_csv(\"/tmp/datos_test.csv\", index=False)\n",
        "df_limpio.to_parquet(\"/tmp/datos_test.parquet\")\n",
        "\n",
        "# Comparar tamano\n",
        "size_csv = os.path.getsize(\"/tmp/datos_test.csv\")\n",
        "size_parquet = os.path.getsize(\"/tmp/datos_test.parquet\")\n",
        "\n",
        "print(f\"CSV:     {size_csv / 1024**2:.2f} MB\")\n",
        "print(f\"Parquet: {size_parquet / 1024**2:.2f} MB\")\n",
        "print(f\"Parquet es {size_csv / size_parquet:.1f}x mas pequeno\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lectura CSV:     0.064s\n",
            "Lectura Parquet: 0.089s\n",
            "Parquet es 0.7x mas rapido\n"
          ]
        }
      ],
      "source": [
        "# Comparar velocidad de lectura\n",
        "t0 = time.perf_counter()\n",
        "_ = pd.read_csv(\"/tmp/datos_test.csv\")\n",
        "t_csv = time.perf_counter() - t0\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "_ = pd.read_parquet(\"/tmp/datos_test.parquet\")\n",
        "t_parquet = time.perf_counter() - t0\n",
        "\n",
        "print(f\"Lectura CSV:     {t_csv:.3f}s\")\n",
        "print(f\"Lectura Parquet: {t_parquet:.3f}s\")\n",
        "print(f\"Parquet es {t_csv / t_parquet:.1f}x mas rapido\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tipos desde CSV (reinferidos):\n",
            "id_cliente    float64\n",
            "nombre         object\n",
            "genero         object\n",
            "edad            int64\n",
            "monto         float64\n",
            "fecha          object\n",
            "activo         object\n",
            "region         object\n",
            "dtype: object\n",
            "\n",
            "Tipos desde Parquet (preservados):\n",
            "id_cliente             Int64\n",
            "nombre        string[python]\n",
            "genero              category\n",
            "edad                   Int16\n",
            "monto                float32\n",
            "fecha         datetime64[ns]\n",
            "activo               boolean\n",
            "region              category\n",
            "dtype: object\n",
            "\n",
            "CSV pierde: nullable ints, categories, datetime, boolean.\n",
            "Parquet preserva todo tal cual lo guardaste.\n"
          ]
        }
      ],
      "source": [
        "# El problema real: CSV pierde tipos\n",
        "df_from_csv = pd.read_csv(\"/tmp/datos_test.csv\")\n",
        "df_from_parquet = pd.read_parquet(\"/tmp/datos_test.parquet\")\n",
        "\n",
        "print(\"Tipos desde CSV (reinferidos):\")\n",
        "print(df_from_csv.dtypes)\n",
        "print()\n",
        "print(\"Tipos desde Parquet (preservados):\")\n",
        "print(df_from_parquet.dtypes)\n",
        "print()\n",
        "print(\"CSV pierde: nullable ints, categories, datetime, boolean.\")\n",
        "print(\"Parquet preserva todo tal cual lo guardaste.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lectura parcial (2 de 8 cols): 0.010s\n",
            "Memoria: 1.40 MB\n",
            "No necesitas cargar 1GB si solo quieres 2 columnas.\n"
          ]
        }
      ],
      "source": [
        "# Bonus: Parquet permite leer solo columnas especificas\n",
        "t0 = time.perf_counter()\n",
        "df_parcial = pd.read_parquet(\"/tmp/datos_test.parquet\", columns=[\"id_cliente\", \"monto\"])\n",
        "t_parcial = time.perf_counter() - t0\n",
        "\n",
        "print(f\"Lectura parcial (2 de {len(df_limpio.columns)} cols): {t_parcial:.3f}s\")\n",
        "print(f\"Memoria: {df_parcial.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(\"No necesitas cargar 1GB si solo quieres 2 columnas.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Profiling: vectorizacion vs apply vs iterrows\n",
        "\n",
        "No todos los caminos para la misma operacion son iguales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset grande para que las diferencias se noten\n",
        "n_bench = 500_000\n",
        "df_bench = pd.DataFrame({\n",
        "    \"precio\": np.random.uniform(10, 1000, n_bench),\n",
        "    \"cantidad\": np.random.randint(1, 50, n_bench),\n",
        "    \"descuento\": np.random.uniform(0, 0.3, n_bench),\n",
        "})\n",
        "\n",
        "# Operacion: total = precio * cantidad * (1 - descuento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorizado: 0.0044s\n"
          ]
        }
      ],
      "source": [
        "# Metodo 1: Vectorizado (el bueno)\n",
        "t0 = time.perf_counter()\n",
        "df_bench[\"total_vec\"] = df_bench[\"precio\"] * df_bench[\"cantidad\"] * (1 - df_bench[\"descuento\"])\n",
        "t_vec = time.perf_counter() - t0\n",
        "print(f\"Vectorizado: {t_vec:.4f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apply:       6.7370s  (1540x mas lento)\n"
          ]
        }
      ],
      "source": [
        "# Metodo 2: apply (el que sugieren los LLMs)\n",
        "t0 = time.perf_counter()\n",
        "df_bench[\"total_apply\"] = df_bench.apply(\n",
        "    lambda row: row[\"precio\"] * row[\"cantidad\"] * (1 - row[\"descuento\"]),\n",
        "    axis=1,\n",
        ")\n",
        "t_apply = time.perf_counter() - t0\n",
        "print(f\"apply:       {t_apply:.4f}s  ({t_apply/t_vec:.0f}x mas lento)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iterrows:    26.1984s estimado (5990x mas lento)\n"
          ]
        }
      ],
      "source": [
        "# Metodo 3: iterrows (el malo)\n",
        "t0 = time.perf_counter()\n",
        "totales = []\n",
        "for _, row in df_bench.head(50_000).iterrows():  # solo 50k para no esperar\n",
        "    totales.append(row[\"precio\"] * row[\"cantidad\"] * (1 - row[\"descuento\"]))\n",
        "t_iter = time.perf_counter() - t0\n",
        "# Escalar al total\n",
        "t_iter_est = t_iter * (n_bench / 50_000)\n",
        "print(f\"iterrows:    {t_iter_est:.4f}s estimado ({t_iter_est/t_vec:.0f}x mas lento)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Resumen de velocidad ===\n",
            "Vectorizado: 0.0044s  (baseline)\n",
            "apply:       6.7370s  (1540x mas lento)\n",
            "iterrows:    26.1984s  (5990x mas lento, estimado)\n",
            "\n",
            "Si un LLM te sugiere .apply(axis=1), preguntate:\n",
            "¿Hay una operacion vectorizada que haga lo mismo?\n",
            "En el 80% de los casos la respuesta es si.\n"
          ]
        }
      ],
      "source": [
        "# Resumen\n",
        "print(\"\\n=== Resumen de velocidad ===\")\n",
        "print(f\"Vectorizado: {t_vec:.4f}s  (baseline)\")\n",
        "print(f\"apply:       {t_apply:.4f}s  ({t_apply/t_vec:.0f}x mas lento)\")\n",
        "print(f\"iterrows:    {t_iter_est:.4f}s  ({t_iter_est/t_vec:.0f}x mas lento, estimado)\")\n",
        "print()\n",
        "print(\"Si un LLM te sugiere .apply(axis=1), preguntate:\")\n",
        "print(\"¿Hay una operacion vectorizada que haga lo mismo?\")\n",
        "print(\"En el 80% de los casos la respuesta es si.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Ejercicios\n",
        "\n",
        "### Ejercicio 1: Diagnostico\n",
        "Usa `df_sucio` y responde:\n",
        "- ¿Cuanta memoria usa?\n",
        "- ¿Que columnas son `object` y podrian ser `category`?\n",
        "- ¿Hay columnas numericas que fueron promovidas a `float` por missings?\n",
        "\n",
        "### Ejercicio 2: Pipeline\n",
        "Toma el `df_sucio` y construye tu propio pipeline con `.pipe()` que:\n",
        "1. Valide que tiene al menos 4 columnas\n",
        "2. Normalice los nombres de columnas\n",
        "3. Limpie missings disfrazados en columnas de texto\n",
        "4. Convierta `fecha` a datetime\n",
        "5. Exporte a Parquet\n",
        "\n",
        "Incluye al menos 2 `assert` entre pasos.\n",
        "\n",
        "### Ejercicio 3: Optimizacion\n",
        "El siguiente codigo es lento. Reescribelo usando operaciones vectorizadas:\n",
        "\n",
        "```python\n",
        "# Codigo lento — reescribir\n",
        "df[\"categoria\"] = df[\"monto\"].apply(\n",
        "    lambda x: \"alto\" if x > 1000 else (\"medio\" if x > 100 else \"bajo\")\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Espacio para resolver ejercicios\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Resumen\n",
        "\n",
        "| Concepto | Clave |\n",
        "|----------|-------|\n",
        "| `np.nan` | Es float → promueve int a float, bool a object |\n",
        "| `pd.NA` + nullable dtypes | El futuro: `Int64`, `Float64`, `boolean`, `string` |\n",
        "| Missings en texto | Normalizar `\"\"`, `\"N/A\"`, `\"null\"`, etc. antes de analizar |\n",
        "| Memoria | `info(memory_usage='deep')`, `category`, downcast |\n",
        "| Pipeline | Funciones `df → df`, `.pipe()`, asserts entre pasos |\n",
        "| Parquet > CSV | Mas rapido, mas pequeno, preserva tipos |\n",
        "| Vectorizar > apply | 10-100x de diferencia, siempre buscar la alternativa vectorizada |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
